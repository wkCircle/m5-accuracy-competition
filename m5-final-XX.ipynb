{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Konstantin Yakovlev, Matthias Anderer\n",
    "\n",
    "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "   you may not use this file except in compliance with the License.\n",
    "   You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "   Unless required by applicable law or agreed to in writing, software\n",
    "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "   See the License for the specific language governing permissions and\n",
    "   limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "import pathlib\n",
    "import lightgbm as lgb\n",
    "\n",
    "# custom imports\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Helpers\n",
    "#################################################################################\n",
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss func hyperparamter: LOSS_MUTIPLIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_MULTIPLIER = 1.0 # Set multiplier according to desired under-/overshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom loss function\n",
    "def custom_asymmetric_train(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    grad = np.where(residual < 0, -2 * residual, -2 * residual * LOSS_MULTIPLIER)\n",
    "    hess = np.where(residual < 0, 2, 2 * LOSS_MULTIPLIER)\n",
    "    return grad, hess\n",
    "\n",
    "# define custom evaluation metric\n",
    "def custom_asymmetric_valid(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    loss = np.where(residual < 0, (residual ** 2) , (residual ** 2) * LOSS_MULTIPLIER) \n",
    "    return \"custom_asymmetric_eval\", np.mean(loss), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Helper to load data by store ID\n",
    "#################################################################################\n",
    "# Read data\n",
    "def get_data_by_store(store):\n",
    "    \n",
    "    # Read and contact basic feature\n",
    "    df = pd.concat([pd.read_pickle(BASE),\n",
    "                    pd.read_pickle(PRICE).iloc[:,2:],\n",
    "                    pd.read_pickle(CALENDAR).iloc[:,2:]],\n",
    "                    axis=1)\n",
    "    \n",
    "    # Leave only relevant store\n",
    "    df = df[df['store_id']==store]\n",
    "    \n",
    "    ############\n",
    "    # Create features list\n",
    "    features = [col for col in list(df) if col not in remove_features]\n",
    "    df = df[['id','d',TARGET]+features]\n",
    "    \n",
    "    # Skipping first n rows\n",
    "    df = df[df['d']>=START_TRAIN].reset_index(drop=True)\n",
    "    \n",
    "    return df, features\n",
    "\n",
    "# Recombine Test set after training\n",
    "def get_base_test():\n",
    "    base_test = pd.DataFrame()\n",
    "\n",
    "    for store_id in STORES_IDS:\n",
    "        temp_df = pd.read_pickle(output_parent/f'test_{store_id}.pkl')\n",
    "        temp_df['store_id'] = store_id\n",
    "        base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "    \n",
    "    return base_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized Variables Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model params\n",
    "#################################################################################\n",
    "lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'tweedie',\n",
    "        'tweedie_variance_power': 1.1,\n",
    "        'metric':'rmse',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'learning_rate': 0.2,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 1, \n",
    "        'colsample_bytree': 0.85,\n",
    "        'colsample_bynode': 0.85,\n",
    "        #'min_data_per_leaf': 25,\n",
    "        #'num_leaves': 200,\n",
    "        'lambda_l1': 0.5,\n",
    "        'lambda_l2': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stores ids are: ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n"
     ]
    }
   ],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "VER = 1                          # Our model version\n",
    "SEED = 42                        # We want all things\n",
    "seed_everything(SEED)            # to be as deterministic \n",
    "lgb_params['seed'] = SEED        # as possible\n",
    "N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "\n",
    "#LIMITS and const\n",
    "TARGET      = 'sales'            # Our target\n",
    "START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "END_TRAIN   = 1913+28            # End day of our train set\n",
    "P_HORIZON   = 28                 # Prediction horizon\n",
    "USE_AUX     = False               # Use or not pretrained models\n",
    "\n",
    "#FEATURES to remove\n",
    "## These features lead to overfit\n",
    "## or values not present in test set\n",
    "remove_features = ['id','state_id','store_id',\n",
    "                   'date','wm_yr_wk','d',TARGET]\n",
    "\n",
    "#PATHS for Features\n",
    "ORIGINAL = pathlib.Path(\"./input/data\")\n",
    "input_parent = pathlib.Path(\"./input/fe_out\")\n",
    "BASE     = input_parent/'grid_part_1.pkl'\n",
    "PRICE    = input_parent/'grid_part_2.pkl'\n",
    "CALENDAR = input_parent/'grid_part_3.pkl'\n",
    "output_parent = pathlib.Path(\"./input/bottom_out\")\n",
    "\n",
    "#STORES ids\n",
    "STORES_IDS = pd.read_csv(ORIGINAL/'sales_train_validation.csv')['store_id']\n",
    "STORES_IDS = list(STORES_IDS.unique())\n",
    "print(\"stores ids are:\", STORES_IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CA_1...\n",
      "[LightGBM] [Info] Saving data to binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Info] Load from binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.487384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4751349, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.56557\tvalid_1's rmse: 2.20605\n",
      "[200]\ttraining's rmse: 2.4639\tvalid_1's rmse: 2.13062\n",
      "[300]\ttraining's rmse: 2.40439\tvalid_1's rmse: 2.10047\n",
      "[400]\ttraining's rmse: 2.36267\tvalid_1's rmse: 2.07737\n",
      "[500]\ttraining's rmse: 2.33112\tvalid_1's rmse: 2.05069\n",
      "[600]\ttraining's rmse: 2.30341\tvalid_1's rmse: 2.04221\n",
      "[700]\ttraining's rmse: 2.27722\tvalid_1's rmse: 2.02615\n",
      "[800]\ttraining's rmse: 2.25612\tvalid_1's rmse: 2.02238\n",
      "[900]\ttraining's rmse: 2.23541\tvalid_1's rmse: 2.00975\n",
      "[1000]\ttraining's rmse: 2.21714\tvalid_1's rmse: 1.99895\n",
      "[1100]\ttraining's rmse: 2.20066\tvalid_1's rmse: 1.97384\n",
      "[1200]\ttraining's rmse: 2.18526\tvalid_1's rmse: 1.9655\n",
      "[1300]\ttraining's rmse: 2.1715\tvalid_1's rmse: 1.96011\n",
      "[1400]\ttraining's rmse: 2.15872\tvalid_1's rmse: 1.94947\n",
      "[1500]\ttraining's rmse: 2.14682\tvalid_1's rmse: 1.94034\n",
      "[1600]\ttraining's rmse: 2.13565\tvalid_1's rmse: 1.93648\n",
      "[1700]\ttraining's rmse: 2.12556\tvalid_1's rmse: 1.9329\n",
      "[1800]\ttraining's rmse: 2.11485\tvalid_1's rmse: 1.92561\n",
      "[1900]\ttraining's rmse: 2.10488\tvalid_1's rmse: 1.92023\n",
      "[2000]\ttraining's rmse: 2.09608\tvalid_1's rmse: 1.91598\n",
      "[2100]\ttraining's rmse: 2.0873\tvalid_1's rmse: 1.91195\n",
      "[2200]\ttraining's rmse: 2.07885\tvalid_1's rmse: 1.9078\n",
      "[2300]\ttraining's rmse: 2.07006\tvalid_1's rmse: 1.89925\n",
      "[2400]\ttraining's rmse: 2.06212\tvalid_1's rmse: 1.89293\n",
      "[2500]\ttraining's rmse: 2.05453\tvalid_1's rmse: 1.88771\n",
      "[2600]\ttraining's rmse: 2.04664\tvalid_1's rmse: 1.88122\n",
      "[2700]\ttraining's rmse: 2.03947\tvalid_1's rmse: 1.87411\n",
      "[2800]\ttraining's rmse: 2.03252\tvalid_1's rmse: 1.86976\n",
      "[2900]\ttraining's rmse: 2.02548\tvalid_1's rmse: 1.86422\n",
      "[3000]\ttraining's rmse: 2.0185\tvalid_1's rmse: 1.85751\n",
      "[3100]\ttraining's rmse: 2.01152\tvalid_1's rmse: 1.85207\n",
      "[3200]\ttraining's rmse: 2.00542\tvalid_1's rmse: 1.84634\n",
      "[3300]\ttraining's rmse: 1.99929\tvalid_1's rmse: 1.8409\n",
      "[3400]\ttraining's rmse: 1.99371\tvalid_1's rmse: 1.83528\n",
      "[3500]\ttraining's rmse: 1.98813\tvalid_1's rmse: 1.83171\n",
      "[3600]\ttraining's rmse: 1.98257\tvalid_1's rmse: 1.82566\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3600]\ttraining's rmse: 1.98257\tvalid_1's rmse: 1.82566\n",
      "Train CA_2...\n",
      "[LightGBM] [Info] Saving data to binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Info] Load from binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.571452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5578\n",
      "[LightGBM] [Info] Number of data points in the train set: 4329697, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.12787\tvalid_1's rmse: 2.02454\n",
      "[200]\ttraining's rmse: 2.07305\tvalid_1's rmse: 1.98646\n",
      "[300]\ttraining's rmse: 2.03202\tvalid_1's rmse: 1.96068\n",
      "[400]\ttraining's rmse: 2.00377\tvalid_1's rmse: 1.93308\n",
      "[500]\ttraining's rmse: 1.98291\tvalid_1's rmse: 1.91434\n",
      "[600]\ttraining's rmse: 1.9649\tvalid_1's rmse: 1.89145\n",
      "[700]\ttraining's rmse: 1.94913\tvalid_1's rmse: 1.88237\n",
      "[800]\ttraining's rmse: 1.93335\tvalid_1's rmse: 1.8691\n",
      "[900]\ttraining's rmse: 1.91991\tvalid_1's rmse: 1.86123\n",
      "[1000]\ttraining's rmse: 1.90846\tvalid_1's rmse: 1.85332\n",
      "[1100]\ttraining's rmse: 1.89827\tvalid_1's rmse: 1.84365\n",
      "[1200]\ttraining's rmse: 1.8881\tvalid_1's rmse: 1.83786\n",
      "[1300]\ttraining's rmse: 1.87791\tvalid_1's rmse: 1.80997\n",
      "[1400]\ttraining's rmse: 1.86893\tvalid_1's rmse: 1.80623\n",
      "[1500]\ttraining's rmse: 1.86035\tvalid_1's rmse: 1.80185\n",
      "[1600]\ttraining's rmse: 1.85165\tvalid_1's rmse: 1.79796\n",
      "[1700]\ttraining's rmse: 1.84396\tvalid_1's rmse: 1.78859\n",
      "[1800]\ttraining's rmse: 1.83681\tvalid_1's rmse: 1.78533\n",
      "[1900]\ttraining's rmse: 1.82935\tvalid_1's rmse: 1.77858\n",
      "[2000]\ttraining's rmse: 1.8224\tvalid_1's rmse: 1.773\n",
      "[2100]\ttraining's rmse: 1.8156\tvalid_1's rmse: 1.76919\n",
      "[2200]\ttraining's rmse: 1.80942\tvalid_1's rmse: 1.76428\n",
      "[2300]\ttraining's rmse: 1.80333\tvalid_1's rmse: 1.76053\n",
      "[2400]\ttraining's rmse: 1.79775\tvalid_1's rmse: 1.75587\n",
      "[2500]\ttraining's rmse: 1.7919\tvalid_1's rmse: 1.74975\n",
      "[2600]\ttraining's rmse: 1.78638\tvalid_1's rmse: 1.74541\n",
      "[2700]\ttraining's rmse: 1.78116\tvalid_1's rmse: 1.74043\n",
      "[2800]\ttraining's rmse: 1.77579\tvalid_1's rmse: 1.73579\n",
      "[2900]\ttraining's rmse: 1.77085\tvalid_1's rmse: 1.73223\n",
      "[3000]\ttraining's rmse: 1.76568\tvalid_1's rmse: 1.7295\n",
      "[3100]\ttraining's rmse: 1.76096\tvalid_1's rmse: 1.7261\n",
      "[3200]\ttraining's rmse: 1.75616\tvalid_1's rmse: 1.72189\n",
      "[3300]\ttraining's rmse: 1.75157\tvalid_1's rmse: 1.71786\n",
      "[3400]\ttraining's rmse: 1.74761\tvalid_1's rmse: 1.71395\n",
      "[3500]\ttraining's rmse: 1.7431\tvalid_1's rmse: 1.71165\n",
      "[3600]\ttraining's rmse: 1.73883\tvalid_1's rmse: 1.7078\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3600]\ttraining's rmse: 1.73883\tvalid_1's rmse: 1.7078\n",
      "Train CA_3...\n",
      "[LightGBM] [Info] Saving data to binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Info] Load from binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.386484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5673\n",
      "[LightGBM] [Info] Number of data points in the train set: 4720563, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 3.50939\tvalid_1's rmse: 2.63475\n",
      "[200]\ttraining's rmse: 3.36208\tvalid_1's rmse: 2.56691\n",
      "[300]\ttraining's rmse: 3.26495\tvalid_1's rmse: 2.52561\n",
      "[400]\ttraining's rmse: 3.19273\tvalid_1's rmse: 2.47942\n",
      "[500]\ttraining's rmse: 3.14176\tvalid_1's rmse: 2.44954\n",
      "[600]\ttraining's rmse: 3.09375\tvalid_1's rmse: 2.41226\n",
      "[700]\ttraining's rmse: 3.05493\tvalid_1's rmse: 2.37876\n",
      "[800]\ttraining's rmse: 3.02457\tvalid_1's rmse: 2.363\n",
      "[900]\ttraining's rmse: 2.99785\tvalid_1's rmse: 2.34931\n",
      "[1000]\ttraining's rmse: 2.97014\tvalid_1's rmse: 2.34108\n",
      "[1100]\ttraining's rmse: 2.94679\tvalid_1's rmse: 2.33223\n",
      "[1200]\ttraining's rmse: 2.92231\tvalid_1's rmse: 2.31765\n",
      "[1300]\ttraining's rmse: 2.90125\tvalid_1's rmse: 2.30365\n",
      "[1400]\ttraining's rmse: 2.88204\tvalid_1's rmse: 2.29374\n",
      "[1500]\ttraining's rmse: 2.86493\tvalid_1's rmse: 2.28478\n",
      "[1600]\ttraining's rmse: 2.84803\tvalid_1's rmse: 2.2774\n",
      "[1700]\ttraining's rmse: 2.83123\tvalid_1's rmse: 2.26444\n",
      "[1800]\ttraining's rmse: 2.81613\tvalid_1's rmse: 2.25826\n",
      "[1900]\ttraining's rmse: 2.80199\tvalid_1's rmse: 2.2498\n",
      "[2000]\ttraining's rmse: 2.78808\tvalid_1's rmse: 2.24297\n",
      "[2100]\ttraining's rmse: 2.77404\tvalid_1's rmse: 2.23756\n",
      "Early stopping, best iteration is:\n",
      "[2056]\ttraining's rmse: 2.78004\tvalid_1's rmse: 2.23735\n",
      "Train CA_4...\n",
      "[LightGBM] [Info] Saving data to binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Info] Load from binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.479932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5631\n",
      "[LightGBM] [Info] Number of data points in the train set: 4620050, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 1.53561\tvalid_1's rmse: 1.41825\n",
      "[200]\ttraining's rmse: 1.50157\tvalid_1's rmse: 1.40782\n",
      "[300]\ttraining's rmse: 1.47952\tvalid_1's rmse: 1.39284\n",
      "[400]\ttraining's rmse: 1.46465\tvalid_1's rmse: 1.38365\n",
      "[500]\ttraining's rmse: 1.45162\tvalid_1's rmse: 1.37645\n",
      "[600]\ttraining's rmse: 1.44036\tvalid_1's rmse: 1.36644\n",
      "[700]\ttraining's rmse: 1.43015\tvalid_1's rmse: 1.36214\n",
      "[800]\ttraining's rmse: 1.42121\tvalid_1's rmse: 1.35552\n",
      "[900]\ttraining's rmse: 1.41343\tvalid_1's rmse: 1.35068\n",
      "[1000]\ttraining's rmse: 1.40568\tvalid_1's rmse: 1.3456\n",
      "[1100]\ttraining's rmse: 1.39906\tvalid_1's rmse: 1.34047\n",
      "[1200]\ttraining's rmse: 1.39239\tvalid_1's rmse: 1.33793\n",
      "[1300]\ttraining's rmse: 1.38608\tvalid_1's rmse: 1.33442\n",
      "[1400]\ttraining's rmse: 1.38018\tvalid_1's rmse: 1.33089\n",
      "[1500]\ttraining's rmse: 1.3746\tvalid_1's rmse: 1.32726\n",
      "[1600]\ttraining's rmse: 1.36945\tvalid_1's rmse: 1.3249\n",
      "[1700]\ttraining's rmse: 1.36475\tvalid_1's rmse: 1.32163\n",
      "[1800]\ttraining's rmse: 1.3602\tvalid_1's rmse: 1.31877\n",
      "[1900]\ttraining's rmse: 1.35558\tvalid_1's rmse: 1.31604\n",
      "[2000]\ttraining's rmse: 1.35122\tvalid_1's rmse: 1.31306\n",
      "[2100]\ttraining's rmse: 1.34706\tvalid_1's rmse: 1.31054\n",
      "[2200]\ttraining's rmse: 1.3428\tvalid_1's rmse: 1.30836\n",
      "[2300]\ttraining's rmse: 1.3387\tvalid_1's rmse: 1.30611\n",
      "[2400]\ttraining's rmse: 1.33465\tvalid_1's rmse: 1.30275\n",
      "[2500]\ttraining's rmse: 1.3309\tvalid_1's rmse: 1.30004\n",
      "[2600]\ttraining's rmse: 1.32725\tvalid_1's rmse: 1.29741\n",
      "[2700]\ttraining's rmse: 1.3236\tvalid_1's rmse: 1.29248\n",
      "[2800]\ttraining's rmse: 1.32005\tvalid_1's rmse: 1.28892\n",
      "[2900]\ttraining's rmse: 1.31642\tvalid_1's rmse: 1.28618\n",
      "[3000]\ttraining's rmse: 1.31296\tvalid_1's rmse: 1.28378\n",
      "[3100]\ttraining's rmse: 1.30991\tvalid_1's rmse: 1.28111\n",
      "[3200]\ttraining's rmse: 1.30697\tvalid_1's rmse: 1.27864\n",
      "[3300]\ttraining's rmse: 1.3038\tvalid_1's rmse: 1.27523\n",
      "[3400]\ttraining's rmse: 1.3008\tvalid_1's rmse: 1.27094\n",
      "[3500]\ttraining's rmse: 1.29754\tvalid_1's rmse: 1.2685\n",
      "[3600]\ttraining's rmse: 1.29453\tvalid_1's rmse: 1.26587\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3600]\ttraining's rmse: 1.29453\tvalid_1's rmse: 1.26587\n",
      "Train TX_1...\n",
      "[LightGBM] [Info] Saving data to binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Info] Load from binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.407994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5689\n",
      "[LightGBM] [Info] Number of data points in the train set: 4761863, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.13683\tvalid_1's rmse: 1.79455\n",
      "[200]\ttraining's rmse: 2.05733\tvalid_1's rmse: 1.74394\n",
      "[300]\ttraining's rmse: 2.01114\tvalid_1's rmse: 1.70207\n",
      "[400]\ttraining's rmse: 1.97499\tvalid_1's rmse: 1.6708\n",
      "[500]\ttraining's rmse: 1.94585\tvalid_1's rmse: 1.64144\n",
      "[600]\ttraining's rmse: 1.92228\tvalid_1's rmse: 1.63083\n",
      "[700]\ttraining's rmse: 1.9028\tvalid_1's rmse: 1.6091\n",
      "[800]\ttraining's rmse: 1.88391\tvalid_1's rmse: 1.59781\n",
      "[900]\ttraining's rmse: 1.86827\tvalid_1's rmse: 1.59181\n",
      "[1000]\ttraining's rmse: 1.85204\tvalid_1's rmse: 1.58651\n",
      "[1100]\ttraining's rmse: 1.83849\tvalid_1's rmse: 1.57963\n",
      "[1200]\ttraining's rmse: 1.82575\tvalid_1's rmse: 1.56564\n",
      "[1300]\ttraining's rmse: 1.81382\tvalid_1's rmse: 1.55849\n",
      "[1400]\ttraining's rmse: 1.80277\tvalid_1's rmse: 1.54976\n",
      "[1500]\ttraining's rmse: 1.79099\tvalid_1's rmse: 1.54311\n",
      "[1600]\ttraining's rmse: 1.78086\tvalid_1's rmse: 1.53802\n",
      "[1700]\ttraining's rmse: 1.77118\tvalid_1's rmse: 1.53113\n",
      "[1800]\ttraining's rmse: 1.76265\tvalid_1's rmse: 1.52763\n",
      "[1900]\ttraining's rmse: 1.75454\tvalid_1's rmse: 1.51632\n",
      "[2000]\ttraining's rmse: 1.74636\tvalid_1's rmse: 1.51069\n",
      "[2100]\ttraining's rmse: 1.73845\tvalid_1's rmse: 1.50717\n",
      "[2200]\ttraining's rmse: 1.73068\tvalid_1's rmse: 1.50374\n",
      "[2300]\ttraining's rmse: 1.72403\tvalid_1's rmse: 1.49886\n",
      "[2400]\ttraining's rmse: 1.71681\tvalid_1's rmse: 1.49471\n",
      "[2500]\ttraining's rmse: 1.70934\tvalid_1's rmse: 1.4916\n",
      "[2600]\ttraining's rmse: 1.7029\tvalid_1's rmse: 1.48625\n",
      "[2700]\ttraining's rmse: 1.69701\tvalid_1's rmse: 1.48186\n",
      "[2800]\ttraining's rmse: 1.69069\tvalid_1's rmse: 1.47537\n",
      "[2900]\ttraining's rmse: 1.6847\tvalid_1's rmse: 1.47191\n",
      "[3000]\ttraining's rmse: 1.67878\tvalid_1's rmse: 1.46796\n",
      "[3100]\ttraining's rmse: 1.67323\tvalid_1's rmse: 1.46433\n",
      "[3200]\ttraining's rmse: 1.66817\tvalid_1's rmse: 1.46018\n",
      "[3300]\ttraining's rmse: 1.66228\tvalid_1's rmse: 1.45833\n",
      "[3400]\ttraining's rmse: 1.65744\tvalid_1's rmse: 1.45346\n",
      "[3500]\ttraining's rmse: 1.65238\tvalid_1's rmse: 1.44966\n",
      "[3600]\ttraining's rmse: 1.64699\tvalid_1's rmse: 1.44702\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3600]\ttraining's rmse: 1.64699\tvalid_1's rmse: 1.44702\n",
      "Train TX_2...\n",
      "[LightGBM] [Info] Saving data to binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Info] Load from binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.463588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5682\n",
      "[LightGBM] [Info] Number of data points in the train set: 4771138, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.5516\tvalid_1's rmse: 1.91614\n",
      "[200]\ttraining's rmse: 2.43971\tvalid_1's rmse: 1.87061\n",
      "[300]\ttraining's rmse: 2.37585\tvalid_1's rmse: 1.83758\n",
      "[400]\ttraining's rmse: 2.32442\tvalid_1's rmse: 1.81263\n",
      "[500]\ttraining's rmse: 2.28565\tvalid_1's rmse: 1.79435\n",
      "[600]\ttraining's rmse: 2.25461\tvalid_1's rmse: 1.77964\n",
      "[700]\ttraining's rmse: 2.22616\tvalid_1's rmse: 1.7688\n",
      "[800]\ttraining's rmse: 2.20414\tvalid_1's rmse: 1.75742\n",
      "[900]\ttraining's rmse: 2.18288\tvalid_1's rmse: 1.74497\n",
      "[1000]\ttraining's rmse: 2.16302\tvalid_1's rmse: 1.7288\n",
      "[1100]\ttraining's rmse: 2.14384\tvalid_1's rmse: 1.72327\n",
      "[1200]\ttraining's rmse: 2.12825\tvalid_1's rmse: 1.71786\n",
      "[1300]\ttraining's rmse: 2.11238\tvalid_1's rmse: 1.70935\n",
      "[1400]\ttraining's rmse: 2.09689\tvalid_1's rmse: 1.70276\n",
      "[1500]\ttraining's rmse: 2.08429\tvalid_1's rmse: 1.6992\n",
      "[1600]\ttraining's rmse: 2.07096\tvalid_1's rmse: 1.69158\n",
      "[1700]\ttraining's rmse: 2.05883\tvalid_1's rmse: 1.68644\n",
      "[1800]\ttraining's rmse: 2.04725\tvalid_1's rmse: 1.68211\n",
      "[1900]\ttraining's rmse: 2.03553\tvalid_1's rmse: 1.67333\n",
      "[2000]\ttraining's rmse: 2.02397\tvalid_1's rmse: 1.67024\n",
      "[2100]\ttraining's rmse: 2.01475\tvalid_1's rmse: 1.66519\n",
      "[2200]\ttraining's rmse: 2.00535\tvalid_1's rmse: 1.66121\n",
      "[2300]\ttraining's rmse: 1.99543\tvalid_1's rmse: 1.6559\n",
      "[2400]\ttraining's rmse: 1.98612\tvalid_1's rmse: 1.65059\n",
      "[2500]\ttraining's rmse: 1.9775\tvalid_1's rmse: 1.64621\n",
      "[2600]\ttraining's rmse: 1.96949\tvalid_1's rmse: 1.64273\n",
      "[2700]\ttraining's rmse: 1.96108\tvalid_1's rmse: 1.64003\n",
      "[2800]\ttraining's rmse: 1.95364\tvalid_1's rmse: 1.63611\n",
      "[2900]\ttraining's rmse: 1.94622\tvalid_1's rmse: 1.63364\n",
      "[3000]\ttraining's rmse: 1.93843\tvalid_1's rmse: 1.62856\n",
      "[3100]\ttraining's rmse: 1.93174\tvalid_1's rmse: 1.62185\n",
      "[3200]\ttraining's rmse: 1.92523\tvalid_1's rmse: 1.61837\n",
      "[3300]\ttraining's rmse: 1.91785\tvalid_1's rmse: 1.61469\n",
      "[3400]\ttraining's rmse: 1.91081\tvalid_1's rmse: 1.60922\n",
      "[3500]\ttraining's rmse: 1.90411\tvalid_1's rmse: 1.60581\n",
      "[3600]\ttraining's rmse: 1.89751\tvalid_1's rmse: 1.60152\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3600]\ttraining's rmse: 1.89751\tvalid_1's rmse: 1.60152\n",
      "Train TX_3...\n",
      "[LightGBM] [Info] Saving data to binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Info] Load from binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.596024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5680\n",
      "[LightGBM] [Info] Number of data points in the train set: 4702580, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.21241\tvalid_1's rmse: 2.04669\n",
      "[200]\ttraining's rmse: 2.11833\tvalid_1's rmse: 1.96322\n",
      "[300]\ttraining's rmse: 2.06221\tvalid_1's rmse: 1.92247\n",
      "[400]\ttraining's rmse: 2.02189\tvalid_1's rmse: 1.90481\n",
      "[500]\ttraining's rmse: 1.99017\tvalid_1's rmse: 1.8684\n",
      "[600]\ttraining's rmse: 1.96331\tvalid_1's rmse: 1.84516\n",
      "[700]\ttraining's rmse: 1.9401\tvalid_1's rmse: 1.83347\n",
      "[800]\ttraining's rmse: 1.92016\tvalid_1's rmse: 1.82222\n",
      "[900]\ttraining's rmse: 1.9027\tvalid_1's rmse: 1.80753\n",
      "[1000]\ttraining's rmse: 1.88762\tvalid_1's rmse: 1.79617\n",
      "[1100]\ttraining's rmse: 1.87345\tvalid_1's rmse: 1.78603\n",
      "[1200]\ttraining's rmse: 1.85891\tvalid_1's rmse: 1.77585\n",
      "[1300]\ttraining's rmse: 1.84572\tvalid_1's rmse: 1.76684\n",
      "[1400]\ttraining's rmse: 1.83369\tvalid_1's rmse: 1.76019\n",
      "[1500]\ttraining's rmse: 1.82269\tvalid_1's rmse: 1.7496\n",
      "[1600]\ttraining's rmse: 1.81292\tvalid_1's rmse: 1.74038\n",
      "[1700]\ttraining's rmse: 1.80306\tvalid_1's rmse: 1.72882\n",
      "[1800]\ttraining's rmse: 1.79337\tvalid_1's rmse: 1.71973\n",
      "[1900]\ttraining's rmse: 1.78502\tvalid_1's rmse: 1.71052\n",
      "[2000]\ttraining's rmse: 1.7757\tvalid_1's rmse: 1.70282\n",
      "[2100]\ttraining's rmse: 1.76791\tvalid_1's rmse: 1.69779\n",
      "[2200]\ttraining's rmse: 1.76029\tvalid_1's rmse: 1.69105\n",
      "[2300]\ttraining's rmse: 1.75266\tvalid_1's rmse: 1.68541\n",
      "[2400]\ttraining's rmse: 1.74521\tvalid_1's rmse: 1.67983\n",
      "[2500]\ttraining's rmse: 1.73798\tvalid_1's rmse: 1.66957\n",
      "[2600]\ttraining's rmse: 1.73142\tvalid_1's rmse: 1.66385\n",
      "[2700]\ttraining's rmse: 1.72508\tvalid_1's rmse: 1.65681\n",
      "[2800]\ttraining's rmse: 1.71869\tvalid_1's rmse: 1.65026\n",
      "[2900]\ttraining's rmse: 1.7126\tvalid_1's rmse: 1.64392\n",
      "[3000]\ttraining's rmse: 1.70647\tvalid_1's rmse: 1.63869\n",
      "[3100]\ttraining's rmse: 1.70093\tvalid_1's rmse: 1.63236\n",
      "[3200]\ttraining's rmse: 1.69493\tvalid_1's rmse: 1.62846\n",
      "[3300]\ttraining's rmse: 1.68912\tvalid_1's rmse: 1.62435\n",
      "[3400]\ttraining's rmse: 1.68337\tvalid_1's rmse: 1.62013\n",
      "[3500]\ttraining's rmse: 1.6781\tvalid_1's rmse: 1.61673\n",
      "[3600]\ttraining's rmse: 1.67325\tvalid_1's rmse: 1.61371\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3600]\ttraining's rmse: 1.67325\tvalid_1's rmse: 1.61371\n",
      "Train WI_1...\n",
      "[LightGBM] [Info] Saving data to binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Info] Load from binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.572059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5653\n",
      "[LightGBM] [Info] Number of data points in the train set: 4532270, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 1.76925\tvalid_1's rmse: 1.69106\n",
      "[200]\ttraining's rmse: 1.71869\tvalid_1's rmse: 1.6614\n",
      "[300]\ttraining's rmse: 1.68772\tvalid_1's rmse: 1.63912\n",
      "[400]\ttraining's rmse: 1.66583\tvalid_1's rmse: 1.62217\n",
      "[500]\ttraining's rmse: 1.64849\tvalid_1's rmse: 1.60933\n",
      "[600]\ttraining's rmse: 1.63456\tvalid_1's rmse: 1.60022\n",
      "[700]\ttraining's rmse: 1.6229\tvalid_1's rmse: 1.59133\n",
      "[800]\ttraining's rmse: 1.61055\tvalid_1's rmse: 1.5833\n",
      "[900]\ttraining's rmse: 1.60034\tvalid_1's rmse: 1.57498\n",
      "[1000]\ttraining's rmse: 1.59134\tvalid_1's rmse: 1.56768\n",
      "[1100]\ttraining's rmse: 1.583\tvalid_1's rmse: 1.56007\n",
      "[1200]\ttraining's rmse: 1.5742\tvalid_1's rmse: 1.54772\n",
      "[1300]\ttraining's rmse: 1.56694\tvalid_1's rmse: 1.54234\n",
      "[1400]\ttraining's rmse: 1.56028\tvalid_1's rmse: 1.53639\n",
      "[1500]\ttraining's rmse: 1.55388\tvalid_1's rmse: 1.52966\n",
      "[1600]\ttraining's rmse: 1.54732\tvalid_1's rmse: 1.52515\n",
      "[1700]\ttraining's rmse: 1.54202\tvalid_1's rmse: 1.52007\n",
      "[1800]\ttraining's rmse: 1.53661\tvalid_1's rmse: 1.51547\n",
      "[1900]\ttraining's rmse: 1.53074\tvalid_1's rmse: 1.51205\n",
      "[2000]\ttraining's rmse: 1.52533\tvalid_1's rmse: 1.50662\n",
      "[2100]\ttraining's rmse: 1.52049\tvalid_1's rmse: 1.50284\n",
      "[2200]\ttraining's rmse: 1.51585\tvalid_1's rmse: 1.50037\n",
      "[2300]\ttraining's rmse: 1.5113\tvalid_1's rmse: 1.49375\n",
      "[2400]\ttraining's rmse: 1.50689\tvalid_1's rmse: 1.49019\n",
      "[2500]\ttraining's rmse: 1.50236\tvalid_1's rmse: 1.48763\n",
      "[2600]\ttraining's rmse: 1.49801\tvalid_1's rmse: 1.48206\n",
      "[2700]\ttraining's rmse: 1.49402\tvalid_1's rmse: 1.4789\n",
      "[2800]\ttraining's rmse: 1.49038\tvalid_1's rmse: 1.47622\n",
      "[2900]\ttraining's rmse: 1.48652\tvalid_1's rmse: 1.47248\n",
      "[3000]\ttraining's rmse: 1.48272\tvalid_1's rmse: 1.46871\n",
      "[3100]\ttraining's rmse: 1.479\tvalid_1's rmse: 1.46515\n",
      "[3200]\ttraining's rmse: 1.47532\tvalid_1's rmse: 1.46188\n",
      "[3300]\ttraining's rmse: 1.47183\tvalid_1's rmse: 1.45881\n",
      "[3400]\ttraining's rmse: 1.46866\tvalid_1's rmse: 1.45675\n",
      "[3500]\ttraining's rmse: 1.46528\tvalid_1's rmse: 1.45442\n",
      "[3600]\ttraining's rmse: 1.46215\tvalid_1's rmse: 1.45278\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3600]\ttraining's rmse: 1.46215\tvalid_1's rmse: 1.45278\n",
      "Train WI_2...\n",
      "[LightGBM] [Info] Saving data to binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Info] Load from binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.401698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5673\n",
      "[LightGBM] [Info] Number of data points in the train set: 4618209, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.81381\tvalid_1's rmse: 2.83067\n",
      "[200]\ttraining's rmse: 2.68227\tvalid_1's rmse: 2.72057\n",
      "[300]\ttraining's rmse: 2.60231\tvalid_1's rmse: 2.61626\n",
      "[400]\ttraining's rmse: 2.54226\tvalid_1's rmse: 2.56231\n",
      "[500]\ttraining's rmse: 2.49106\tvalid_1's rmse: 2.49978\n",
      "[600]\ttraining's rmse: 2.44544\tvalid_1's rmse: 2.45405\n",
      "[700]\ttraining's rmse: 2.40909\tvalid_1's rmse: 2.41587\n",
      "[800]\ttraining's rmse: 2.37562\tvalid_1's rmse: 2.38714\n",
      "[900]\ttraining's rmse: 2.3454\tvalid_1's rmse: 2.36478\n",
      "[1000]\ttraining's rmse: 2.31951\tvalid_1's rmse: 2.33715\n",
      "[1100]\ttraining's rmse: 2.29454\tvalid_1's rmse: 2.31017\n",
      "[1200]\ttraining's rmse: 2.27274\tvalid_1's rmse: 2.28894\n",
      "[1300]\ttraining's rmse: 2.25134\tvalid_1's rmse: 2.2706\n",
      "[1400]\ttraining's rmse: 2.23249\tvalid_1's rmse: 2.25254\n",
      "[1500]\ttraining's rmse: 2.21558\tvalid_1's rmse: 2.23033\n",
      "[1600]\ttraining's rmse: 2.19884\tvalid_1's rmse: 2.21762\n",
      "[1700]\ttraining's rmse: 2.18286\tvalid_1's rmse: 2.19354\n",
      "[1800]\ttraining's rmse: 2.16762\tvalid_1's rmse: 2.17336\n",
      "[1900]\ttraining's rmse: 2.15424\tvalid_1's rmse: 2.15819\n",
      "[2000]\ttraining's rmse: 2.13931\tvalid_1's rmse: 2.14919\n",
      "[2100]\ttraining's rmse: 2.12746\tvalid_1's rmse: 2.13617\n",
      "[2200]\ttraining's rmse: 2.11548\tvalid_1's rmse: 2.12706\n",
      "[2300]\ttraining's rmse: 2.10396\tvalid_1's rmse: 2.11944\n",
      "[2400]\ttraining's rmse: 2.09311\tvalid_1's rmse: 2.1099\n",
      "[2500]\ttraining's rmse: 2.08196\tvalid_1's rmse: 2.09523\n",
      "[2600]\ttraining's rmse: 2.07195\tvalid_1's rmse: 2.08575\n",
      "[2700]\ttraining's rmse: 2.06135\tvalid_1's rmse: 2.07565\n",
      "[2800]\ttraining's rmse: 2.05102\tvalid_1's rmse: 2.06605\n",
      "[2900]\ttraining's rmse: 2.04155\tvalid_1's rmse: 2.05773\n",
      "[3000]\ttraining's rmse: 2.03236\tvalid_1's rmse: 2.05003\n",
      "[3100]\ttraining's rmse: 2.02332\tvalid_1's rmse: 2.04373\n",
      "[3200]\ttraining's rmse: 2.01505\tvalid_1's rmse: 2.03739\n",
      "[3300]\ttraining's rmse: 2.00702\tvalid_1's rmse: 2.02896\n",
      "[3400]\ttraining's rmse: 1.99875\tvalid_1's rmse: 2.02206\n",
      "[3500]\ttraining's rmse: 1.99085\tvalid_1's rmse: 2.01641\n",
      "[3600]\ttraining's rmse: 1.98312\tvalid_1's rmse: 2.00814\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3600]\ttraining's rmse: 1.98312\tvalid_1's rmse: 2.00814\n",
      "Train WI_3...\n",
      "[LightGBM] [Info] Saving data to binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Info] Load from binary file input\\bottom_out\\train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.429764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5661\n",
      "[LightGBM] [Info] Number of data points in the train set: 4736383, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.40603\tvalid_1's rmse: 2.04085\n",
      "[200]\ttraining's rmse: 2.29709\tvalid_1's rmse: 1.98749\n",
      "[300]\ttraining's rmse: 2.23175\tvalid_1's rmse: 1.94829\n",
      "[400]\ttraining's rmse: 2.18292\tvalid_1's rmse: 1.91779\n",
      "[500]\ttraining's rmse: 2.14203\tvalid_1's rmse: 1.8906\n",
      "[600]\ttraining's rmse: 2.10887\tvalid_1's rmse: 1.86953\n",
      "[700]\ttraining's rmse: 2.0807\tvalid_1's rmse: 1.85579\n",
      "[800]\ttraining's rmse: 2.0547\tvalid_1's rmse: 1.83493\n",
      "[900]\ttraining's rmse: 2.03221\tvalid_1's rmse: 1.81539\n",
      "[1000]\ttraining's rmse: 2.01247\tvalid_1's rmse: 1.80374\n",
      "[1100]\ttraining's rmse: 1.99443\tvalid_1's rmse: 1.7888\n",
      "[1200]\ttraining's rmse: 1.97774\tvalid_1's rmse: 1.77388\n",
      "[1300]\ttraining's rmse: 1.96275\tvalid_1's rmse: 1.76068\n",
      "[1400]\ttraining's rmse: 1.94707\tvalid_1's rmse: 1.75267\n",
      "[1500]\ttraining's rmse: 1.93398\tvalid_1's rmse: 1.73583\n",
      "[1600]\ttraining's rmse: 1.92201\tvalid_1's rmse: 1.72492\n",
      "[1700]\ttraining's rmse: 1.91007\tvalid_1's rmse: 1.71469\n",
      "[1800]\ttraining's rmse: 1.89898\tvalid_1's rmse: 1.7079\n",
      "[1900]\ttraining's rmse: 1.88875\tvalid_1's rmse: 1.69701\n",
      "[2000]\ttraining's rmse: 1.87783\tvalid_1's rmse: 1.691\n",
      "[2100]\ttraining's rmse: 1.86796\tvalid_1's rmse: 1.6849\n",
      "[2200]\ttraining's rmse: 1.85843\tvalid_1's rmse: 1.67567\n",
      "[2300]\ttraining's rmse: 1.8487\tvalid_1's rmse: 1.66888\n",
      "[2400]\ttraining's rmse: 1.84021\tvalid_1's rmse: 1.66249\n",
      "[2500]\ttraining's rmse: 1.83184\tvalid_1's rmse: 1.65293\n",
      "[2600]\ttraining's rmse: 1.82402\tvalid_1's rmse: 1.64666\n",
      "[2700]\ttraining's rmse: 1.81619\tvalid_1's rmse: 1.6423\n",
      "[2800]\ttraining's rmse: 1.80906\tvalid_1's rmse: 1.63794\n",
      "[2900]\ttraining's rmse: 1.80162\tvalid_1's rmse: 1.63457\n",
      "[3000]\ttraining's rmse: 1.79405\tvalid_1's rmse: 1.62744\n",
      "[3100]\ttraining's rmse: 1.78777\tvalid_1's rmse: 1.62244\n",
      "[3200]\ttraining's rmse: 1.78126\tvalid_1's rmse: 1.61828\n",
      "[3300]\ttraining's rmse: 1.77452\tvalid_1's rmse: 1.6119\n",
      "[3400]\ttraining's rmse: 1.76812\tvalid_1's rmse: 1.60696\n",
      "[3500]\ttraining's rmse: 1.76162\tvalid_1's rmse: 1.60266\n",
      "[3600]\ttraining's rmse: 1.75546\tvalid_1's rmse: 1.60035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3600]\ttraining's rmse: 1.75546\tvalid_1's rmse: 1.60035\n"
     ]
    }
   ],
   "source": [
    "########################### Train Models\n",
    "#################################################################################\n",
    "for store_id in STORES_IDS:\n",
    "    print('Train {}...'.format(store_id))\n",
    "    \n",
    "    # Get grid for current store: 1min\n",
    "    # features_columns is ['item_id', 'dept_id', 'cat_id', 'release', 'sell_price', 'price_max', \n",
    "    # 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', \n",
    "    # 'price_min', 'price_momentum_m', 'price_momentum_y', 'event_name_1', 'event_type_1', \n",
    "    # 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', \n",
    "    # 'tm_y', 'tm_wm', 'tm_dw', 'tm_w_end']\n",
    "    grid_df, features_columns = get_data_by_store(store_id)\n",
    "    \n",
    "    # Masks for \n",
    "    # Train (All data less than 1913)\n",
    "    # \"Validation\" (Last 28 days - not real validatio set)\n",
    "    # Test (All data greater than 1913 day, \n",
    "    #       with some gap for recursive features)\n",
    "    train_mask = grid_df['d'] <= END_TRAIN\n",
    "    valid_mask = train_mask & (grid_df['d'] > (END_TRAIN - P_HORIZON))\n",
    "    preds_mask = grid_df['d'] > (END_TRAIN - 100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "    train_data = lgb.Dataset(grid_df[train_mask][features_columns], \n",
    "                       label=grid_df[train_mask][TARGET])\n",
    "    train_data.save_binary(output_parent/'train_data.bin')\n",
    "    train_data = lgb.Dataset(output_parent/'train_data.bin')\n",
    "    \n",
    "    valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], \n",
    "                       label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "    grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "    keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "    grid_df = grid_df[keep_cols]\n",
    "    grid_df.to_pickle(output_parent/f'test_{store_id}.pkl')\n",
    "    del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "    seed_everything(SEED)\n",
    "    estimator = lgb.train(lgb_params,\n",
    "                          train_data,\n",
    "                          num_boost_round = 3600, # =n_estimators = num_trees\n",
    "                          early_stopping_rounds = 50, \n",
    "                          valid_sets = [train_data, valid_data],\n",
    "                          verbose_eval = 100,\n",
    "                          fobj = custom_asymmetric_train\n",
    "                          )\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "    model_name = f'lgb_model_{store_id}_v{VER}.bin'\n",
    "    pickle.dump(estimator, open(output_parent/model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "    os.remove(output_parent/\"train_data.bin\")\n",
    "    del train_data, valid_data, estimator\n",
    "    gc.collect()\n",
    "    \n",
    "    # \"Keep\" models features for predictions\n",
    "    MODEL_FEATURES = features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>release</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>price_std</th>\n",
       "      <th>price_mean</th>\n",
       "      <th>price_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>tm_d</th>\n",
       "      <th>tm_w</th>\n",
       "      <th>tm_m</th>\n",
       "      <th>tm_y</th>\n",
       "      <th>tm_wm</th>\n",
       "      <th>tm_dw</th>\n",
       "      <th>tm_w_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>4.640625</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>0.146118</td>\n",
       "      <td>4.523438</td>\n",
       "      <td>0.935547</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0</td>\n",
       "      <td>0.419922</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.419922</td>\n",
       "      <td>0.020035</td>\n",
       "      <td>0.475830</td>\n",
       "      <td>0.839844</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_009</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0</td>\n",
       "      <td>1.559570</td>\n",
       "      <td>1.769531</td>\n",
       "      <td>1.559570</td>\n",
       "      <td>0.066345</td>\n",
       "      <td>1.720703</td>\n",
       "      <td>0.881348</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_010</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0</td>\n",
       "      <td>3.169922</td>\n",
       "      <td>3.169922</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>0.028915</td>\n",
       "      <td>2.974609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_012</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0</td>\n",
       "      <td>5.980469</td>\n",
       "      <td>6.519531</td>\n",
       "      <td>5.980469</td>\n",
       "      <td>0.115967</td>\n",
       "      <td>6.468750</td>\n",
       "      <td>0.916992</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736378</th>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>0</td>\n",
       "      <td>2.980469</td>\n",
       "      <td>2.980469</td>\n",
       "      <td>2.480469</td>\n",
       "      <td>0.171631</td>\n",
       "      <td>2.800781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736379</th>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>0</td>\n",
       "      <td>2.480469</td>\n",
       "      <td>2.679688</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.253174</td>\n",
       "      <td>2.507812</td>\n",
       "      <td>0.925293</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736380</th>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>0</td>\n",
       "      <td>3.980469</td>\n",
       "      <td>4.378906</td>\n",
       "      <td>3.980469</td>\n",
       "      <td>0.188599</td>\n",
       "      <td>4.117188</td>\n",
       "      <td>0.908691</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736381</th>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>230</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736382</th>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4736383 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_id    dept_id   cat_id  release  sell_price  price_max  \\\n",
       "0        HOBBIES_1_004  HOBBIES_1  HOBBIES        0    4.339844   4.640625   \n",
       "1        HOBBIES_1_008  HOBBIES_1  HOBBIES        0    0.419922   0.500000   \n",
       "2        HOBBIES_1_009  HOBBIES_1  HOBBIES        0    1.559570   1.769531   \n",
       "3        HOBBIES_1_010  HOBBIES_1  HOBBIES        0    3.169922   3.169922   \n",
       "4        HOBBIES_1_012  HOBBIES_1  HOBBIES        0    5.980469   6.519531   \n",
       "...                ...        ...      ...      ...         ...        ...   \n",
       "4736378    FOODS_3_823    FOODS_3    FOODS        0    2.980469   2.980469   \n",
       "4736379    FOODS_3_824    FOODS_3    FOODS        0    2.480469   2.679688   \n",
       "4736380    FOODS_3_825    FOODS_3    FOODS        0    3.980469   4.378906   \n",
       "4736381    FOODS_3_826    FOODS_3    FOODS      230    1.280273   1.280273   \n",
       "4736382    FOODS_3_827    FOODS_3    FOODS      304    1.000000   1.000000   \n",
       "\n",
       "         price_min  price_std  price_mean  price_norm  ...  snap_CA  snap_TX  \\\n",
       "0         4.339844   0.146118    4.523438    0.935547  ...        0        0   \n",
       "1         0.419922   0.020035    0.475830    0.839844  ...        0        0   \n",
       "2         1.559570   0.066345    1.720703    0.881348  ...        0        0   \n",
       "3         2.970703   0.028915    2.974609    1.000000  ...        0        0   \n",
       "4         5.980469   0.115967    6.468750    0.916992  ...        0        0   \n",
       "...            ...        ...         ...         ...  ...      ...      ...   \n",
       "4736378   2.480469   0.171631    2.800781    1.000000  ...        0        0   \n",
       "4736379   2.000000   0.253174    2.507812    0.925293  ...        0        0   \n",
       "4736380   3.980469   0.188599    4.117188    0.908691  ...        0        0   \n",
       "4736381   1.280273   0.000000    1.280273    1.000000  ...        0        0   \n",
       "4736382   1.000000   0.000000    1.000000    1.000000  ...        0        0   \n",
       "\n",
       "         snap_WI  tm_d  tm_w tm_m tm_y tm_wm tm_dw tm_w_end  \n",
       "0              0    26     8    2    0     4     5        1  \n",
       "1              0    26     8    2    0     4     5        1  \n",
       "2              0    26     8    2    0     4     5        1  \n",
       "3              0    26     8    2    0     4     5        1  \n",
       "4              0    26     8    2    0     4     5        1  \n",
       "...          ...   ...   ...  ...  ...   ...   ...      ...  \n",
       "4736378        0    22    20    5    5     4     6        1  \n",
       "4736379        0    22    20    5    5     4     6        1  \n",
       "4736380        0    22    20    5    5     4     6        1  \n",
       "4736381        0    22    20    5    5     4     6        1  \n",
       "4736382        0    22    20    5    5     4     6        1  \n",
       "\n",
       "[4736383 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df, features_columns = get_data_by_store(store_id)\n",
    "grid_df[train_mask][features_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal base_test by combining all test_storeid.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>release</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>...</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>tm_d</th>\n",
       "      <th>tm_w</th>\n",
       "      <th>tm_m</th>\n",
       "      <th>tm_y</th>\n",
       "      <th>tm_wm</th>\n",
       "      <th>tm_dw</th>\n",
       "      <th>tm_w_end</th>\n",
       "      <th>store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>1842</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>224</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>CA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>1842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>20</td>\n",
       "      <td>3.970703</td>\n",
       "      <td>3.970703</td>\n",
       "      <td>3.970703</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>CA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>1842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>300</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>CA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>1842</td>\n",
       "      <td>2.0</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>5</td>\n",
       "      <td>4.640625</td>\n",
       "      <td>4.640625</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>CA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>1842</td>\n",
       "      <td>5.0</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>16</td>\n",
       "      <td>2.880859</td>\n",
       "      <td>3.080078</td>\n",
       "      <td>2.480469</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>CA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902715</th>\n",
       "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
       "      <td>1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>0</td>\n",
       "      <td>2.980469</td>\n",
       "      <td>2.980469</td>\n",
       "      <td>2.480469</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>WI_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902716</th>\n",
       "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
       "      <td>1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>0</td>\n",
       "      <td>2.480469</td>\n",
       "      <td>2.679688</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>WI_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902717</th>\n",
       "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
       "      <td>1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>0</td>\n",
       "      <td>3.980469</td>\n",
       "      <td>4.378906</td>\n",
       "      <td>3.980469</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>WI_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902718</th>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "      <td>1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>230</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>WI_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902719</th>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "      <td>1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>WI_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3902720 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id     d  sales        item_id    dept_id  \\\n",
       "0        HOBBIES_1_001_CA_1_evaluation  1842    4.0  HOBBIES_1_001  HOBBIES_1   \n",
       "1        HOBBIES_1_002_CA_1_evaluation  1842    0.0  HOBBIES_1_002  HOBBIES_1   \n",
       "2        HOBBIES_1_003_CA_1_evaluation  1842    1.0  HOBBIES_1_003  HOBBIES_1   \n",
       "3        HOBBIES_1_004_CA_1_evaluation  1842    2.0  HOBBIES_1_004  HOBBIES_1   \n",
       "4        HOBBIES_1_005_CA_1_evaluation  1842    5.0  HOBBIES_1_005  HOBBIES_1   \n",
       "...                                ...   ...    ...            ...        ...   \n",
       "3902715    FOODS_3_823_WI_3_evaluation  1969    NaN    FOODS_3_823    FOODS_3   \n",
       "3902716    FOODS_3_824_WI_3_evaluation  1969    NaN    FOODS_3_824    FOODS_3   \n",
       "3902717    FOODS_3_825_WI_3_evaluation  1969    NaN    FOODS_3_825    FOODS_3   \n",
       "3902718    FOODS_3_826_WI_3_evaluation  1969    NaN    FOODS_3_826    FOODS_3   \n",
       "3902719    FOODS_3_827_WI_3_evaluation  1969    NaN    FOODS_3_827    FOODS_3   \n",
       "\n",
       "          cat_id  release  sell_price  price_max  price_min  ...  snap_TX  \\\n",
       "0        HOBBIES      224    8.257812   9.578125   8.257812  ...        1   \n",
       "1        HOBBIES       20    3.970703   3.970703   3.970703  ...        1   \n",
       "2        HOBBIES      300    2.970703   2.970703   2.970703  ...        1   \n",
       "3        HOBBIES        5    4.640625   4.640625   4.339844  ...        1   \n",
       "4        HOBBIES       16    2.880859   3.080078   2.480469  ...        1   \n",
       "...          ...      ...         ...        ...        ...  ...      ...   \n",
       "3902715    FOODS        0    2.980469   2.980469   2.480469  ...        0   \n",
       "3902716    FOODS        0    2.480469   2.679688   2.000000  ...        0   \n",
       "3902717    FOODS        0    3.980469   4.378906   3.980469  ...        0   \n",
       "3902718    FOODS      230    1.280273   1.280273   1.280273  ...        0   \n",
       "3902719    FOODS      304    1.000000   1.000000   1.000000  ...        0   \n",
       "\n",
       "         snap_WI  tm_d  tm_w  tm_m  tm_y  tm_wm  tm_dw tm_w_end store_id  \n",
       "0              0    13     6     2     5      2      5        1     CA_1  \n",
       "1              0    13     6     2     5      2      5        1     CA_1  \n",
       "2              0    13     6     2     5      2      5        1     CA_1  \n",
       "3              0    13     6     2     5      2      5        1     CA_1  \n",
       "4              0    13     6     2     5      2      5        1     CA_1  \n",
       "...          ...   ...   ...   ...   ...    ...    ...      ...      ...  \n",
       "3902715        0    19    24     6     5      3      6        1     WI_3  \n",
       "3902716        0    19    24     6     5      3      6        1     WI_3  \n",
       "3902717        0    19    24     6     5      3      6        1     WI_3  \n",
       "3902718        0    19    24     6     5      3      6        1     WI_3  \n",
       "3902719        0    19    24     6     5      3      6        1     WI_3  \n",
       "\n",
       "[3902720 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict | Day: 1\n",
      "##########  0.38 min round |  0.38 min total |  39845.63 day sales |\n",
      "Predict | Day: 2\n",
      "##########  0.26 min round |  0.64 min total |  36546.00 day sales |\n",
      "Predict | Day: 3\n",
      "##########  0.32 min round |  0.97 min total |  37166.55 day sales |\n",
      "Predict | Day: 4\n",
      "##########  0.40 min round |  1.37 min total |  36662.94 day sales |\n",
      "Predict | Day: 5\n",
      "##########  0.33 min round |  1.70 min total |  41326.16 day sales |\n",
      "Predict | Day: 6\n",
      "##########  0.29 min round |  1.99 min total |  49308.41 day sales |\n",
      "Predict | Day: 7\n",
      "##########  0.29 min round |  2.28 min total |  49667.39 day sales |\n",
      "Predict | Day: 8\n",
      "##########  0.30 min round |  2.58 min total |  43635.76 day sales |\n",
      "Predict | Day: 9\n",
      "##########  0.27 min round |  2.86 min total |  37309.17 day sales |\n",
      "Predict | Day: 10\n",
      "##########  0.30 min round |  3.15 min total |  41456.85 day sales |\n",
      "Predict | Day: 11\n",
      "##########  0.27 min round |  3.43 min total |  42743.78 day sales |\n",
      "Predict | Day: 12\n",
      "##########  0.21 min round |  3.64 min total |  49342.01 day sales |\n",
      "Predict | Day: 13\n",
      "##########  0.21 min round |  3.85 min total |  53644.64 day sales |\n",
      "Predict | Day: 14\n",
      "##########  0.21 min round |  4.06 min total |  55908.54 day sales |\n",
      "Predict | Day: 15\n",
      "##########  0.21 min round |  4.27 min total |  45490.00 day sales |\n",
      "Predict | Day: 16\n",
      "##########  0.22 min round |  4.48 min total |  41481.98 day sales |\n",
      "Predict | Day: 17\n",
      "##########  0.21 min round |  4.70 min total |  41208.68 day sales |\n",
      "Predict | Day: 18\n",
      "##########  0.22 min round |  4.91 min total |  43041.62 day sales |\n",
      "Predict | Day: 19\n",
      "##########  0.21 min round |  5.13 min total |  45302.72 day sales |\n",
      "Predict | Day: 20\n",
      "##########  0.21 min round |  5.34 min total |  55711.25 day sales |\n",
      "Predict | Day: 21\n",
      "##########  0.27 min round |  5.60 min total |  57226.46 day sales |\n",
      "Predict | Day: 22\n",
      "##########  0.35 min round |  5.95 min total |  44740.66 day sales |\n",
      "Predict | Day: 23\n",
      "##########  0.31 min round |  6.26 min total |  42105.98 day sales |\n",
      "Predict | Day: 24\n",
      "##########  0.33 min round |  6.60 min total |  42969.15 day sales |\n",
      "Predict | Day: 25\n",
      "##########  0.29 min round |  6.88 min total |  40322.67 day sales |\n",
      "Predict | Day: 26\n",
      "##########  0.30 min round |  7.19 min total |  44248.13 day sales |\n",
      "Predict | Day: 27\n",
      "##########  0.33 min round |  7.51 min total |  52865.76 day sales |\n",
      "Predict | Day: 28\n",
      "##########  0.30 min round |  7.82 min total |  47262.20 day sales |\n",
      "After collection of predictions per stores and per\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>0.753042</td>\n",
       "      <td>0.688188</td>\n",
       "      <td>0.688751</td>\n",
       "      <td>0.686679</td>\n",
       "      <td>0.768146</td>\n",
       "      <td>0.916658</td>\n",
       "      <td>0.874288</td>\n",
       "      <td>0.901520</td>\n",
       "      <td>0.744240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826474</td>\n",
       "      <td>0.927827</td>\n",
       "      <td>0.892749</td>\n",
       "      <td>0.766914</td>\n",
       "      <td>0.726412</td>\n",
       "      <td>0.720585</td>\n",
       "      <td>0.724602</td>\n",
       "      <td>0.799029</td>\n",
       "      <td>0.944285</td>\n",
       "      <td>0.716593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>0.258061</td>\n",
       "      <td>0.179185</td>\n",
       "      <td>0.179749</td>\n",
       "      <td>0.177677</td>\n",
       "      <td>0.265720</td>\n",
       "      <td>0.410616</td>\n",
       "      <td>0.366975</td>\n",
       "      <td>0.287745</td>\n",
       "      <td>0.235237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313481</td>\n",
       "      <td>0.411217</td>\n",
       "      <td>0.374869</td>\n",
       "      <td>0.268727</td>\n",
       "      <td>0.216486</td>\n",
       "      <td>0.210659</td>\n",
       "      <td>0.214676</td>\n",
       "      <td>0.296547</td>\n",
       "      <td>0.438186</td>\n",
       "      <td>0.371699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.306656</td>\n",
       "      <td>0.300634</td>\n",
       "      <td>0.298563</td>\n",
       "      <td>0.386606</td>\n",
       "      <td>0.524676</td>\n",
       "      <td>0.481036</td>\n",
       "      <td>0.410726</td>\n",
       "      <td>0.363467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435126</td>\n",
       "      <td>0.526038</td>\n",
       "      <td>0.489690</td>\n",
       "      <td>0.391707</td>\n",
       "      <td>0.344716</td>\n",
       "      <td>0.332305</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>0.418192</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.486519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>1.576726</td>\n",
       "      <td>1.512710</td>\n",
       "      <td>1.513273</td>\n",
       "      <td>1.556411</td>\n",
       "      <td>1.859568</td>\n",
       "      <td>2.880035</td>\n",
       "      <td>3.226641</td>\n",
       "      <td>1.765071</td>\n",
       "      <td>1.568762</td>\n",
       "      <td>...</td>\n",
       "      <td>1.872590</td>\n",
       "      <td>2.845898</td>\n",
       "      <td>3.199796</td>\n",
       "      <td>1.546131</td>\n",
       "      <td>1.505628</td>\n",
       "      <td>1.499801</td>\n",
       "      <td>1.549028</td>\n",
       "      <td>1.846013</td>\n",
       "      <td>2.863223</td>\n",
       "      <td>2.817502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>1.019091</td>\n",
       "      <td>0.945465</td>\n",
       "      <td>0.946028</td>\n",
       "      <td>0.943957</td>\n",
       "      <td>1.054895</td>\n",
       "      <td>1.357839</td>\n",
       "      <td>1.305729</td>\n",
       "      <td>1.071401</td>\n",
       "      <td>1.002277</td>\n",
       "      <td>...</td>\n",
       "      <td>1.044939</td>\n",
       "      <td>1.300725</td>\n",
       "      <td>1.344590</td>\n",
       "      <td>1.057527</td>\n",
       "      <td>1.010536</td>\n",
       "      <td>1.004709</td>\n",
       "      <td>1.008726</td>\n",
       "      <td>1.112624</td>\n",
       "      <td>1.412312</td>\n",
       "      <td>1.343253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
       "      <td>0.202623</td>\n",
       "      <td>0.143599</td>\n",
       "      <td>0.124301</td>\n",
       "      <td>0.099602</td>\n",
       "      <td>0.166274</td>\n",
       "      <td>0.314532</td>\n",
       "      <td>0.295167</td>\n",
       "      <td>0.156133</td>\n",
       "      <td>0.142843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221505</td>\n",
       "      <td>0.412340</td>\n",
       "      <td>0.473968</td>\n",
       "      <td>0.263467</td>\n",
       "      <td>0.253557</td>\n",
       "      <td>0.286319</td>\n",
       "      <td>0.184189</td>\n",
       "      <td>0.209371</td>\n",
       "      <td>0.353168</td>\n",
       "      <td>0.336223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
       "      <td>0.158023</td>\n",
       "      <td>0.077515</td>\n",
       "      <td>0.058217</td>\n",
       "      <td>0.033519</td>\n",
       "      <td>0.086313</td>\n",
       "      <td>0.195474</td>\n",
       "      <td>0.181825</td>\n",
       "      <td>0.535540</td>\n",
       "      <td>0.076709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129575</td>\n",
       "      <td>0.354055</td>\n",
       "      <td>0.409779</td>\n",
       "      <td>0.185414</td>\n",
       "      <td>0.280990</td>\n",
       "      <td>0.313752</td>\n",
       "      <td>0.106136</td>\n",
       "      <td>0.125178</td>\n",
       "      <td>0.229878</td>\n",
       "      <td>0.209876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
       "      <td>0.785415</td>\n",
       "      <td>0.726391</td>\n",
       "      <td>0.707093</td>\n",
       "      <td>0.680611</td>\n",
       "      <td>0.733405</td>\n",
       "      <td>0.828566</td>\n",
       "      <td>0.814917</td>\n",
       "      <td>0.661982</td>\n",
       "      <td>0.723801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879478</td>\n",
       "      <td>1.194102</td>\n",
       "      <td>1.227838</td>\n",
       "      <td>0.944876</td>\n",
       "      <td>1.039661</td>\n",
       "      <td>1.046878</td>\n",
       "      <td>0.820935</td>\n",
       "      <td>0.832240</td>\n",
       "      <td>0.948121</td>\n",
       "      <td>0.931320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "      <td>1.121828</td>\n",
       "      <td>1.063728</td>\n",
       "      <td>1.044429</td>\n",
       "      <td>1.005161</td>\n",
       "      <td>0.955275</td>\n",
       "      <td>1.252617</td>\n",
       "      <td>1.109078</td>\n",
       "      <td>1.105437</td>\n",
       "      <td>1.092550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997041</td>\n",
       "      <td>1.338233</td>\n",
       "      <td>1.329249</td>\n",
       "      <td>1.159699</td>\n",
       "      <td>1.195015</td>\n",
       "      <td>1.216385</td>\n",
       "      <td>1.097569</td>\n",
       "      <td>1.013930</td>\n",
       "      <td>1.295008</td>\n",
       "      <td>1.367331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "      <td>1.988957</td>\n",
       "      <td>1.766601</td>\n",
       "      <td>1.516146</td>\n",
       "      <td>1.439374</td>\n",
       "      <td>1.599284</td>\n",
       "      <td>1.762151</td>\n",
       "      <td>1.900428</td>\n",
       "      <td>2.831550</td>\n",
       "      <td>1.893559</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001932</td>\n",
       "      <td>1.157930</td>\n",
       "      <td>1.272154</td>\n",
       "      <td>1.795013</td>\n",
       "      <td>1.779932</td>\n",
       "      <td>1.769018</td>\n",
       "      <td>1.662136</td>\n",
       "      <td>1.833926</td>\n",
       "      <td>1.980528</td>\n",
       "      <td>2.330426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        F1        F2        F3        F4  \\\n",
       "0      HOBBIES_1_001_CA_1_evaluation  0.753042  0.688188  0.688751  0.686679   \n",
       "1      HOBBIES_1_002_CA_1_evaluation  0.258061  0.179185  0.179749  0.177677   \n",
       "2      HOBBIES_1_003_CA_1_evaluation  0.380282  0.306656  0.300634  0.298563   \n",
       "3      HOBBIES_1_004_CA_1_evaluation  1.576726  1.512710  1.513273  1.556411   \n",
       "4      HOBBIES_1_005_CA_1_evaluation  1.019091  0.945465  0.946028  0.943957   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "30485    FOODS_3_823_WI_3_evaluation  0.202623  0.143599  0.124301  0.099602   \n",
       "30486    FOODS_3_824_WI_3_evaluation  0.158023  0.077515  0.058217  0.033519   \n",
       "30487    FOODS_3_825_WI_3_evaluation  0.785415  0.726391  0.707093  0.680611   \n",
       "30488    FOODS_3_826_WI_3_evaluation  1.121828  1.063728  1.044429  1.005161   \n",
       "30489    FOODS_3_827_WI_3_evaluation  1.988957  1.766601  1.516146  1.439374   \n",
       "\n",
       "             F5        F6        F7        F8        F9  ...       F19  \\\n",
       "0      0.768146  0.916658  0.874288  0.901520  0.744240  ...  0.826474   \n",
       "1      0.265720  0.410616  0.366975  0.287745  0.235237  ...  0.313481   \n",
       "2      0.386606  0.524676  0.481036  0.410726  0.363467  ...  0.435126   \n",
       "3      1.859568  2.880035  3.226641  1.765071  1.568762  ...  1.872590   \n",
       "4      1.054895  1.357839  1.305729  1.071401  1.002277  ...  1.044939   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "30485  0.166274  0.314532  0.295167  0.156133  0.142843  ...  0.221505   \n",
       "30486  0.086313  0.195474  0.181825  0.535540  0.076709  ...  0.129575   \n",
       "30487  0.733405  0.828566  0.814917  0.661982  0.723801  ...  0.879478   \n",
       "30488  0.955275  1.252617  1.109078  1.105437  1.092550  ...  0.997041   \n",
       "30489  1.599284  1.762151  1.900428  2.831550  1.893559  ...  1.001932   \n",
       "\n",
       "            F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0      0.927827  0.892749  0.766914  0.726412  0.720585  0.724602  0.799029   \n",
       "1      0.411217  0.374869  0.268727  0.216486  0.210659  0.214676  0.296547   \n",
       "2      0.526038  0.489690  0.391707  0.344716  0.332305  0.336321  0.418192   \n",
       "3      2.845898  3.199796  1.546131  1.505628  1.499801  1.549028  1.846013   \n",
       "4      1.300725  1.344590  1.057527  1.010536  1.004709  1.008726  1.112624   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "30485  0.412340  0.473968  0.263467  0.253557  0.286319  0.184189  0.209371   \n",
       "30486  0.354055  0.409779  0.185414  0.280990  0.313752  0.106136  0.125178   \n",
       "30487  1.194102  1.227838  0.944876  1.039661  1.046878  0.820935  0.832240   \n",
       "30488  1.338233  1.329249  1.159699  1.195015  1.216385  1.097569  1.013930   \n",
       "30489  1.157930  1.272154  1.795013  1.779932  1.769018  1.662136  1.833926   \n",
       "\n",
       "            F27       F28  \n",
       "0      0.944285  0.716593  \n",
       "1      0.438186  0.371699  \n",
       "2      0.553006  0.486519  \n",
       "3      2.863223  2.817502  \n",
       "4      1.412312  1.343253  \n",
       "...         ...       ...  \n",
       "30485  0.353168  0.336223  \n",
       "30486  0.229878  0.209876  \n",
       "30487  0.948121  0.931320  \n",
       "30488  1.295008  1.367331  \n",
       "30489  1.980528  2.330426  \n",
       "\n",
       "[30490 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################### Predict\n",
    "#################################################################################\n",
    "\n",
    "# Create Dummy DataFrame to store predictions\n",
    "all_preds = pd.DataFrame()\n",
    "\n",
    "# Join back the Test dataset with \n",
    "# a small part of the training data \n",
    "# to make recursive features\n",
    "base_test = get_base_test()\n",
    "print(\"orginal base_test by combining all test_storeid.pkl\")\n",
    "display(base_test)\n",
    "\n",
    "# Timer to measure predictions time \n",
    "main_time = time.time()\n",
    "\n",
    "# Loop over each prediction day\n",
    "# As rolling lags are the most timeconsuming\n",
    "# we will calculate it for whole day\n",
    "for PREDICT_DAY in range(1,29):    \n",
    "    print('Predict | Day:', PREDICT_DAY)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Make temporary grid to calculate rolling lags\n",
    "    grid_df = base_test.copy()\n",
    "        \n",
    "    for store_id in STORES_IDS:\n",
    "        \n",
    "        # Read all our models and make predictions\n",
    "        # for each day/store pairs\n",
    "        model_name = f'lgb_model_{store_id}_v{VER}.bin' \n",
    "        if USE_AUX: # use pretrained models \n",
    "            model_name = AUX_MODEL + model_name\n",
    "        \n",
    "        estimator = pickle.load(open(output_parent/model_name, 'rb'))\n",
    "        \n",
    "        day_mask = base_test['d']==(END_TRAIN + PREDICT_DAY)\n",
    "        store_mask = base_test['store_id']==store_id\n",
    "        \n",
    "        mask = (day_mask) & (store_mask)\n",
    "        base_test[TARGET][mask] = estimator.predict(grid_df[mask][MODEL_FEATURES])\n",
    "    \n",
    "    # Make good column naming and add \n",
    "    # to all_preds DataFrame\n",
    "    temp_df = base_test[day_mask][['id',TARGET]]\n",
    "    temp_df.columns = ['id', f'F{PREDICT_DAY}']\n",
    "    if 'id' in list(all_preds):\n",
    "        all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n",
    "    else:\n",
    "        all_preds = temp_df.copy()\n",
    "        \n",
    "    print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n",
    "                  ' %0.2f min total |' % ((time.time() - main_time) / 60),\n",
    "                  ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n",
    "    del temp_df\n",
    "    \n",
    "all_preds = all_preds.reset_index(drop=True)\n",
    "print(\"After collection of predictions per stores and per\")\n",
    "display(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Export\n",
    "#################################################################################\n",
    "# Reading competition sample submission and\n",
    "# merging our predictions\n",
    "# As we have predictions only for \"_validation\" data\n",
    "# we need to do fillna() for \"_evaluation\" items\n",
    "submission = pd.read_csv(ORIGINAL/'sample_submission.csv')[['id']]\n",
    "submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n",
    "submission.to_csv(output_parent/f'submission_v{VER}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('poetry-modeling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b9fdaeeb7f23b80181d796b81c382cf57b09494118cd09f4f1f2649b466761a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
